{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▌                                                                              | 16/495 [01:13<22:22,  2.80s/it]"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Nov  4 14:56:42 2016\n",
    "@author: Artem\n",
    "\"\"\"\n",
    "from IPython.display import clear_output\n",
    "import requests\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "#Библиотека содержит\n",
    "import get_data_dic\n",
    "import distr\n",
    "from tqdm import tqdm\n",
    "#Вывод на экран текущего времени (час, мин)\n",
    "localtime = time.localtime(time.time())\n",
    "print (\"Local current time :\", localtime[3:5])\n",
    "#Ссылкы на первую страницу выдачи при поиске\n",
    "#квартир из определенного района при поиске квартир из ЦАО\n",
    "def split_link(link):\n",
    "    return link.split('/')[-2]\n",
    "time_list =[]\n",
    "progress_list = []\n",
    "mln_boarders=[]\n",
    "for mln_price in range(5,500,1):\n",
    "    mln_boarders.append(mln_price*100000)\n",
    "parsed_files_list_names =[ 'data29_01_2017__21_29_12ADD.csv',\n",
    "                   'data30_01_2017__00_04_43ADD.csv',\n",
    "                         'FINAL_data30_01_2017__06_33_11ADD.csv']\n",
    "def add_path(filename):\n",
    "    big_files_path = 'output/big_files/'\n",
    "    return big_files_path + filename\n",
    "parsed_files_list = list(map(add_path,parsed_files_list_names))\n",
    "print(parsed_files_list)\n",
    "parsed_df = []\n",
    "for parsed_file in parsed_files_list:\n",
    "    df1 = pd.read_csv(parsed_file,sep=';',encoding='cp1251')\n",
    "    if len(parsed_df)!=0:\n",
    "        parsed_df = pd.concat([parsed_df,df1])\n",
    "    else:\n",
    "        parsed_df = df1.copy()\n",
    "parsed_links = list(parsed_df['Link'])\n",
    "#print(parsed_links)\n",
    "parsed_links = list(map(split_link,parsed_links))\n",
    "#print(parsed_links[0:10])\n",
    "dist_list =[]\n",
    "dist_list_show=[]\n",
    "min_boarder=0\n",
    "for boarder in mln_boarders:\n",
    "    a = 'https://www.cian.ru/cat.php?currency=2&deal_type=sale&engine_version=2'\n",
    "    b = '&maxprice=' + str(boarder)\n",
    "    c = '&minprice=' + str(min_boarder+1)\n",
    "    d = '&offer_type=flat&'\n",
    "    e = 'p={}'\n",
    "    f = '&region=1&room1=1&room2=1&room3=1&room4=1&room5=1&room6=1&room7=1&room9=1'\n",
    "    dist_list_show.append(' from ' + str(min_boarder/1000000) + ' to ' + str(boarder/1000000)+' mln')\n",
    "    min_boarder = boarder\n",
    "    abcdef = a + b + c + d + e + f\n",
    "    #print(abcdef)\n",
    "    dist_list.append(abcdef)\n",
    "#print(dist_list)\n",
    "#dist_list=[cent]\n",
    "#X - будущий большой датасет со всеми квартирами и фичами\n",
    "N=30 #число страниц, по которым мы бегаем, ища\n",
    "X=[]#all data\n",
    "#Цикл по всем районам. Номер района в цикле это и есть номер,\n",
    "#под которым этот районом будет закодирован в конечном датасете\n",
    "ID=0 #номер квартиры в датасете\n",
    "for distN in tqdm(range( len(dist_list) )):\n",
    "    #print(dist_list_show[distN])\n",
    "    time1 = time.localtime(time.time())\n",
    "    #print (\"Local current time :\", time1[3:5])\n",
    "    #по главной ссылке находим номера страниц каждой из квартир\n",
    "    #например, на нулевой итерации links - список уникальных номеров всех\n",
    "    #квартир из ЦАО\n",
    "    links=distr.links( dist_list[distN],N )\n",
    "    #пробегаем во всем квартирам в округе\n",
    "    print(len(links),end=' - > ')\n",
    "    filt_links = []\n",
    "    for link in links:\n",
    "        if (str(link) ) not in parsed_links:\n",
    "            filt_links.append(link)\n",
    "    print(len(filt_links))\n",
    "    link_loop_couter = 0\n",
    "    for link in filt_links:\n",
    "        \n",
    "        if (link_loop_couter%30==0)|(link_loop_couter==10):\n",
    "            print(link_loop_couter+1,') ', time.strftime(\"%H_%M_%S\"),end= ' ')\n",
    "        link_loop_couter+=1\n",
    "        #словарь из фич для данной квартиры\n",
    "        ind_data_dic=get_data_dic.get_data_dic (link)\n",
    "        #добавляем поле District, которое зависит от района\n",
    "        ind_data_dic['Search_group']=dist_list_show[distN]\n",
    "        ind_data_dic['ID']=ID\n",
    "        ind_data_dic['Link']='http://www.cian.ru/sale/flat/' + str(link) + '/'\n",
    "        ind_data_dic['parsing_date'] = time.strftime(\"%d_%m_%Y\")\n",
    "        ID+=1\n",
    "        #добавляем словарь фич для квартиры в итоговый датасет    \n",
    "        X.append(ind_data_dic)\n",
    "    #print(\"preparing data\")\n",
    "    data=pd.DataFrame(X)\n",
    "    time_list.append(datetime.datetime.utcnow())\n",
    "    progress_list.append(len(data))\n",
    "    #print(str(distN) + '/' + str(len(dist_list)))\n",
    "    data.to_csv(\"output\\data\" +time.strftime(\"%d_%m_%Y\")+'__'+ time.strftime(\"%H_%M_%S\") +'ADD' +\".csv\",sep=';')\n",
    "    clear_output()\n",
    "    #plt.plot(time_list,progress_list)\n",
    "    #plt.show()\n",
    "data.to_csv(\"output\\FINAL_data\" +time.strftime(\"%d_%m_%Y\")+'__'+ time.strftime(\"%H_%M_%S\") +'ADD'+ \".csv\",sep=';')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25570"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i in range(3):\n",
    "    print(i,end=' ')\n",
    "    time_list.append(datetime.datetime.utcnow())\n",
    "    progress_list.append(i)\n",
    "    time.sleep(1)\n",
    "import datetime\n",
    "\n",
    "datetime.datetime.utcnow()\n",
    "\n",
    "plt.plot(time_list,progress_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "strftime() takes at least 1 argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-db6a30676d28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: strftime() takes at least 1 argument (0 given)"
     ]
    }
   ],
   "source": [
    "time.strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def heat_map(x,y):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    heatmap, xedges, yedges = np.histogram2d(x, y, bins=200)\n",
    "    extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "    plt.clf()\n",
    "    #plt.figure(figsize=(10,5))\n",
    "    plt.imshow(heatmap.T, extent=extent, origin='lower')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
